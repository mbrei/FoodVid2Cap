{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate captions for the test set \n",
    "This notebook contains code that produces the prediction probabilities and corresponding captions for an unseen test dataset which is compromised by 7 recipe types that were never seen during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "#specify the root path for importing modules\n",
    "sys.path.append(\"C:/Users/User/foodcap\")\n",
    "\n",
    "#misc\n",
    "import src.config as config\n",
    "from src.data.data_loading import get_loader\n",
    "from src.data.load_build_vocab import Vocabulary\n",
    "from src.utils import create_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMARK: The parameter recipe1M_embeddings and resNet have to be set such that they match the training setting of the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe1M_embeddings = True\n",
    "resNet = True\n",
    "\n",
    "#Specify the folder and model name which should be loaded\n",
    "model_folder = '../models/2019-08-02_17-12-01/'\n",
    "model_name = \"last_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "if recipe1M_embeddings:\n",
    "    vocab_path = '../data/vocab_recipe1M.pkl'\n",
    "else:\n",
    "    vocab_path = \"../data/vocab.pkl\"\n",
    "    \n",
    "data_dir = config.DATA[\"data_dir\"]\n",
    "feature_dir = data_dir + \"resnet_features/\"\n",
    "num_workers = 0\n",
    "\n",
    "limit_test = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vocabulary and index data file for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load vocabulary\n",
      "Vocab size 30462\n"
     ]
    }
   ],
   "source": [
    "print(\"Load vocabulary\")\n",
    "# Load vocabulary wrapper\n",
    "with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "vocab_size= len(vocab)\n",
    "print(\"Vocab size\",vocab_size)\n",
    "\n",
    "yc2_all = pd.read_csv(\"../data/data_all.csv\")\n",
    "\n",
    "\n",
    "test_idx = yc2_all[yc2_all.subset_new == \"test\"].index\n",
    "yc2_test = yc2_all.iloc[test_idx]\n",
    "yc2_test_small = yc2_test[['video_seg_id','recipe_label','sentence','recipe_index']]\n",
    "\n",
    "bs = len(yc2_test_small)\n",
    "\n",
    "del yc2_all\n",
    "del yc2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model_folder+model_name)\n",
    "decoder = model.decoder\n",
    "\n",
    "data_loader_test = get_loader(feature_dir, yc2_test_small, vocab, decoder, batch_size = bs ,\n",
    "                            shuffle=True, num_workers=num_workers, data_dir = data_dir, resnet = resNet, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate prediction probabilities for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, captions_test, x_lengths_test, y_lengths_test, x_recipe_types = next(iter(data_loader_test))\n",
    "seq_probs_test = model(vocab, x_test, x_lengths_test, captions_test, x_recipe_types, teaching_forcing_ratio =0,\n",
    "                       limit= limit_test, train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer the predicted probabilities to the corresponding words from the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(yc2_test_small.shape[0], vocab, seq_probs_test, captions_test)\n",
    "with open(model_folder+\"predictions_test_\"+model_name+\".json\", 'w') as f:\n",
    "    f.write(json.dumps(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
